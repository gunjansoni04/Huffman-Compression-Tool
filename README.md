# ğŸ—œï¸ Huffman Compression & Decompression Tool  
### Built using Python | Streamlit | Data Compression Algorithm

---

## ğŸ“– Project Overview
This project implements **Huffman Encoding and Decoding** â€” a lossless data compression algorithm.  
It allows users to upload a text file, compress it efficiently using **Static or Adaptive Huffman Coding**, and then decompress it back to its original form.

It also includes a modern **Streamlit Web Interface** for easy interaction, visualization, and report generation.

---

## ğŸ¯ Objectives
- To design and implement a **lossless compression algorithm** using Huffman Coding.  
- To visualize **compression ratios** and compare original vs. compressed sizes.  
- To provide a simple, user-friendly **web UI** using Streamlit.  
- To implement an **Adaptive Huffman** version for real-time compression simulation.  
- To demonstrate algorithmic concepts like **Greedy technique**, **Divide & Conquer**, and **Complexity Analysis**.

---

## âš™ï¸ System Architecture
The system follows a modular design:
User Interface (Streamlit)
â†“
Input & Preprocessing
â†“
Huffman Encoder / Adaptive Encoder
â†“
Compressed File (.huff) + Code Mapping (codes.txt)
â†“
Huffman Decoder
â†“
Decompressed Output + Reports

ğŸ–¼ï¸ *Refer to the architecture diagram in the repository.*

---

## ğŸ’» Features
- ğŸ“¦ **Text Compression:** Upload `.txt` files and compress them into `.huff` format.  
- ğŸª¶ **Decompression:** Reconstruct original text using generated `codes.txt`.  
- âš¡ **Dual Modes:**  
  - **Static Huffman Encoding**  
  - **Adaptive Huffman Encoding (Real-time)**  
- ğŸ“Š **Visualization:** Compare file sizes with bar charts.  
- ğŸ“„ **Auto Summary Report:** Generates compression statistics automatically.  
- ğŸŒ **Web-based Interface:** Built with Streamlit â€” no installation hassles.

---

## ğŸ§  Algorithm Concepts Used
- **Design and Analysis Concepts:**  
  - Greedy Algorithm (Huffman Coding)  
  - Complexity Analysis (O(n log n))  
  - Divide and Conquer (Tree Construction)  
  - Empirical Complexity via Profiling  

- **Complexity Overview:**  
  - Building Frequency Table â†’ O(n)  
  - Building Huffman Tree â†’ O(k log k)  
  - Encoding â†’ O(n)  
  - Decoding â†’ O(n)

---

## ğŸš€ How to Run the Project

### ğŸ§© 1. Clone the Repository
```bash
git clone https://github.com/gunjansoni04/Huffman-Compression-Tool.git
cd Huffman-Compression-Tool

3. Run the Streamlit App
streamlit run app.py


Then open the local URL shown in the terminal.

ğŸ“Š Sample Output
Metric	Example Result
Original Size	3800 bits
Compressed Size	849 bits
Compression Ratio	77.66%
Encoding Time	0.0003 sec
ğŸ§© Files & Structure
ğŸ“‚ HuffmanProject
 â”£ ğŸ“„ app.py                â†’ Streamlit interface
 â”£ ğŸ“„ huffman.py            â†’ Huffman encoding/decoding logic
 â”£ ğŸ“„ adaptive_demo.py      â†’ Adaptive Huffman simulation
 â”£ ğŸ“‚ data/                 â†’ Sample text files (English, Hindi, Marathi, Tamil)
 â”£ ğŸ“„ codes.txt             â†’ Code mapping for decoding
 â”£ ğŸ“„ compressed_output.huffâ†’ Compressed file output
 â”— ğŸ“„ README.md             â†’ Project documentation

ğŸ§¾ Report Highlights

Algorithm Used: Huffman Coding (Greedy Approach)

Programming Language: Python

Tools: Streamlit, Matplotlib

Dataset: Custom multilingual text samples

Extension: Adaptive Huffman Algorithm (Dynamic frequency update)

ğŸ‘©â€ğŸ’» Author

Gunjan Soni
Department of Artificial Intelligence & Data Science
Vishwakarma Institute of Information Technology, Pune

ğŸ“š References

Huffman, D. A. â€œA Method for the Construction of Minimum-Redundancy Codes.â€ Proceedings of the IRE, 1952.

Streamlit Documentation: https://docs.streamlit.io

GeeksforGeeks: Huffman Coding Algorithm

